# **YT-RAGSense**

A modular, blazing-fast Retrieval-Augmented Generation (RAG) system powered by:

- Groq LLMs (Llama 3.x, Mixtral)

- Typesense / FAISS vector stores

- LangChain Community

- HuggingFace Embeddings

Built for developers who want a clean, production-ready RAG pipeline for YouTube transcripts, documents, or any custom dataset.


## Table of Contents

- Features
- Project Architecture
- Screenshots
- Project Structure
- Installation
- Environment Variables
- Build Vector Index
- Run Query
- Tech Stack
- Contributing
- License

## ğŸš€ Features

- Ultra-fast inference using Groq Llama 3
- RAG over YouTube transcripts, PDFs, text, JSONL
- High-performance semantic search (Typesense / FAISS)
- Clean modular architecture (src/)
- Plug-and-play embedding + vector store pipeline
- Includes notebook for debugging + experimentation

## Project Structure
```
YT-RAGSense/
â”‚
â”œâ”€â”€ data/                 
â”œâ”€â”€ faiss_store/          
â”œâ”€â”€ notebook/             
â”‚   â””â”€â”€ typesense.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ loaders/            # All data loaders
â”‚   â”œâ”€â”€ embedding/          # Embedding pipeline
â”‚   â”œâ”€â”€ vectorstore/        # Typesense + FAISS handlers
â”‚   â”œâ”€â”€ llm/                # Groq LLM wrapper
â”‚   â””â”€â”€ rag_pipeline.py     # Main RAG logic
â”‚
â”œâ”€â”€ app.py                  # Build index
â”œâ”€â”€ main.py                 # Query tester
â”œâ”€â”€ books.jsonl
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```
<img width="750" height="355" alt="medium_simple_rag_workflow_091648ef39" src="https://github.com/user-attachments/assets/2cb8e8c8-2dea-44fd-9c61-b07ab739912d" />



## ğŸ› ï¸ Installation
### 1. Clone Repo
```
git clone https://github.com/Sathya-2006/YT-RAGSense.git
cd YT-RAGSense
```

### 2. Create Environment (Using UV â€” Recommended)
**Create environment**
 ```  uv venv```
**Activate**
   **Windows:** ``` .venv\Scripts\activate ```
  

### 3. Install dependencies
 ```  uv pip install -r requirements.txt ```

### 4. Environment Variables
**Create a .env file:**
```GROQ_API_KEY=your_api_key
TYPESENSE_API_KEY=your_typesense_key
TYPESENSE_HOST=ziktplh30uqsjbw6p-1.a1.typesense.net
TYPESENSE_PORT=443
TYPESENSE_PROTOCOL=https
```
### Build Vector Index
 ```
python app.py
```
**This will:**
âœ” Load data
âœ” Split text
âœ” Generate embeddings
âœ” Store vectors in Typesense / FAISS

### Run Query
```
python main.py
```


**Example usage:**
```
from src.rag_pipeline import ask_rag
print(ask_rag("What is Generative AI?"))
```
# Tech Stack
- Python 3.10+
- Typesense / FAISS
- Groq API (Llama 3.x, Mixtral)
- LangChain Community
- HuggingFace Embeddings
- UV (Virtual environment + package manager)

## ğŸ¤ Contributing

Pull requests, issues, and suggestions are welcome!

## ğŸ“„ License

MIT License

## â­ Support

If you like this repo, consider giving it a star â­ on GitHub!
